{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"C:/Users/Victor Daugaard/Desktop/White hair test/PAT_79_120_739.png\")\n",
    "mask = cv.imread(\"C:/Users/Victor Daugaard/Desktop/White hair test/PAT_79_120_739_mask.png\")\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrastor not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT NEEDED!!!\n",
    "def contraster(img,contrast, reverse=False):\n",
    "    # Takes a contrast vector in bgr\n",
    "    \n",
    "    # Copy the image and turn it into floats\n",
    "    # Makes it possible to work with 0-1 range\n",
    "    tmp = img.copy()\n",
    "    tmp = tmp.astype(float)\n",
    "    \n",
    "    # Find dimensions of image to loop through all pixels\n",
    "    dimensions = list(np.shape(tmp))[:2]\n",
    "    \n",
    "    # Loop through all pixels\n",
    "    for x in range(dimensions[0]):\n",
    "        for y in range(dimensions[1]):\n",
    "            # bgr color, b=0   g = 1   r = 2\n",
    "            \n",
    "            # Convert range from 0-255 to 0-1\n",
    "            tmp[x,y,2] = tmp[x,y,2] / 255\n",
    "            tmp[x,y,1] = tmp[x,y,1] / 255\n",
    "            tmp[x,y,0] = tmp[x,y,0] / 255\n",
    "            \n",
    "            # Apply contrasting\n",
    "            tmp[x,y,2] = (tmp[x,y,2]-0.5) * contrast[2] + 0.5\n",
    "            tmp[x,y,1] = (tmp[x,y,1]-0.5) * contrast[1] + 0.5\n",
    "            tmp[x,y,0] = (tmp[x,y,0]-0.5) * contrast[0] + 0.5\n",
    "            \n",
    "            # Reverse colors if reverse=True\n",
    "            if reverse == True:\n",
    "                tmp[x,y,2] = tmp[x,y,2] * -1 + 1\n",
    "                tmp[x,y,1] = tmp[x,y,1] * -1 + 1\n",
    "                tmp[x,y,0] = tmp[x,y,0] * -1 + 1\n",
    "            \n",
    "            # Convert range from 0-1 to 0-255\n",
    "            tmp[x,y,2] = tmp[x,y,2] * 255\n",
    "            tmp[x,y,1] = tmp[x,y,1] * 255\n",
    "            tmp[x,y,0] = tmp[x,y,0] * 255\n",
    "    \n",
    "    # Change the color value type to uint8, clamp between 0 - 255, and return\n",
    "    # Maybe consider a tonemapper instead of clamp\n",
    "    return np.clip(tmp.astype(np.uint8), 0, 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saturator not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT NEEDED!!!!!!!!\n",
    "def saturator(img,saturation):\n",
    "    # Takes a saturation vector in bgr\n",
    "    \n",
    "    # Copy the image and turn it into floats\n",
    "    # Makes it possible to work with 0-1 range\n",
    "    tmp = img.copy()\n",
    "    tmp = tmp.astype(float)\n",
    "    \n",
    "    # Find dimensions of image to loop through all pixels\n",
    "    dimensions = list(np.shape(tmp))[:2]\n",
    "    \n",
    "    # Loop through all pixels\n",
    "    for x in range(dimensions[0]):\n",
    "        for y in range(dimensions[1]):\n",
    "            # bgr color, b=0   g = 1   r = 2\n",
    "            \n",
    "            # Convert range from 0-255 to 0-1\n",
    "            tmp[x,y,2] = tmp[x,y,2] / 255\n",
    "            tmp[x,y,1] = tmp[x,y,1] / 255\n",
    "            tmp[x,y,0] = tmp[x,y,0] / 255\n",
    "            \n",
    "            # Calculate luminance of pixel\n",
    "            luminance = [0,0,0]\n",
    "            luminance[2] = tmp[x,y,2] * 0.299\n",
    "            luminance[1] = tmp[x,y,1] * 0.574\n",
    "            luminance[0] = tmp[x,y,0] * 0.127\n",
    "            \n",
    "            # Apply saturation\n",
    "            tmp[x,y,2] = tmp[x,y,2] * saturation[2] + luminance[2] * (1-saturation[2])\n",
    "            tmp[x,y,1] = tmp[x,y,1] * saturation[1] + luminance[1] * (1-saturation[1])\n",
    "            tmp[x,y,0] = tmp[x,y,0] * saturation[0] + luminance[0] * (1-saturation[0])\n",
    "            \n",
    "            # Convert range from 0-1 to 0-255\n",
    "            tmp[x,y,2] = tmp[x,y,2] * 255\n",
    "            tmp[x,y,1] = tmp[x,y,1] * 255\n",
    "            tmp[x,y,0] = tmp[x,y,0] * 255\n",
    "    \n",
    "    # Change the color value type to uint8, clamp between 0 - 255, and return\n",
    "    # Maybe consider a tonemapper instead of clamp\n",
    "    return np.clip(tmp.astype(np.uint8), 0, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeHair(img_org, img_gray, kernel_size=25, threshold=10, radius=3):\n",
    "    # kernel for the morphological filtering\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_CROSS, (kernel_size, kernel_size))\n",
    "\n",
    "    # perform the blackHat filtering on the grayscale image to find the hair countours\n",
    "    blackhat = cv.morphologyEx(img_gray, cv.MORPH_BLACKHAT, kernel)\n",
    "\n",
    "    # intensify the hair countours in preparation for the inpainting algorithm\n",
    "    _, thresh = cv.threshold(blackhat, threshold, 255, cv.THRESH_BINARY)\n",
    "\n",
    "    # inpaint the original image depending on the mask\n",
    "    img_out = cv.inpaint(img_org, thresh, radius, cv.INPAINT_TELEA)\n",
    "\n",
    "    return blackhat, thresh, img_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeHairWhite(img_org, kernel_size=25, threshold=10, radius=3):\n",
    "\n",
    "    # Color reverser start\n",
    "    # Copy the image and turn it into floats\n",
    "    # Makes it possible to work with 0-1 range\n",
    "    img_reverse = img.copy()\n",
    "    img_reverse = img_reverse.astype(float)\n",
    "    \n",
    "    # Find dimensions of image to loop through all pixels\n",
    "    dimensions = list(np.shape(img_reverse))[:2]\n",
    "    \n",
    "    # Loop through all pixels\n",
    "    for x in range(dimensions[0]):\n",
    "        for y in range(dimensions[1]):\n",
    "            # bgr color, b=0   g = 1   r = 2\n",
    "            \n",
    "            # Convert range from 0-255 to 0-1\n",
    "            img_reverse[x,y,2] = img_reverse[x,y,2] / 255\n",
    "            img_reverse[x,y,1] = img_reverse[x,y,1] / 255\n",
    "            img_reverse[x,y,0] = img_reverse[x,y,0] / 255\n",
    "            \n",
    "            # Reverse colors to make black -> white and white -> black\n",
    "            img_reverse[x,y,2] = img_reverse[x,y,2] * -1 + 1\n",
    "            img_reverse[x,y,1] = img_reverse[x,y,1] * -1 + 1\n",
    "            img_reverse[x,y,0] = img_reverse[x,y,0] * -1 + 1\n",
    "            \n",
    "            # Convert range from 0-1 to 0-255\n",
    "            img_reverse[x,y,2] = img_reverse[x,y,2] * 255\n",
    "            img_reverse[x,y,1] = img_reverse[x,y,1] * 255\n",
    "            img_reverse[x,y,0] = img_reverse[x,y,0] * 255\n",
    "    \n",
    "    img_reverse = np.clip(img_reverse.astype(np.uint8), 0, 255)\n",
    "    # Color reverser end\n",
    "    \n",
    "    gray_reverse = cv.cvtColor(img_reverse, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # kernel for the morphological filtering\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_CROSS, (kernel_size, kernel_size))\n",
    "\n",
    "    # perform the blackHat filtering on the grayscale image to find the hair countours\n",
    "    blackhat = cv.morphologyEx(gray_reverse, cv.MORPH_BLACKHAT, kernel)\n",
    "\n",
    "    # intensify the hair countours in preparation for the inpainting algorithm\n",
    "    _, thresh = cv.threshold(blackhat, threshold, 255, cv.THRESH_BINARY)\n",
    "\n",
    "    # inpaint the original image depending on the mask\n",
    "    img_out = cv.inpaint(img_org, thresh, radius, cv.INPAINT_TELEA)\n",
    "\n",
    "    return blackhat, thresh, img_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# White hair removal\n",
    "_, _, img_out1 = removeHairWhite(img)\n",
    "\n",
    "# Black hair removal\n",
    "_, _, img_out2 = removeHair(img,gray)\n",
    "\n",
    "# Black hair removal, then white hair removal\n",
    "# _, _, img_out3 = removeHairWhite(img_out2)\n",
    "\n",
    "# White then black\n",
    "# _, _, img_out4 = removeHair(img_out1, gray)\n",
    "\n",
    "# Creating masked images\n",
    "# masked = cv.bitwise_and(img, mask)\n",
    "# masked_removed = cv.bitwise_and(img_out1, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow(\"Image\", img)\n",
    "cv.imshow(\"White hair removed image\", img_out1)\n",
    "cv.imshow(\"Black hair removed image\", img_out2)\n",
    "# cv.imshow(\"Black then white hair removed image\", img_out3)\n",
    "# cv.imshow(\"White then black hair removed image\", img_out4)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"White then black\" is better than \"black then white\".\n",
    "\n",
    "It changes the image drastically either way, so not sure if it's very good to do that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
